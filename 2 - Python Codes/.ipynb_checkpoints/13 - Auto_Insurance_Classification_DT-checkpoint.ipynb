{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src= 'https://www.bbds.ma/wp-content/uploads/2021/04/logo.jpg' width=300/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Guide  \n",
    "------------  \n",
    "- [Project Overview](#project-overview)  \n",
    "- [Part 1: Reading Data - Exploratory Data Analysis with Pandas](#I)\n",
    "- [Part 2: Visual data analysis in Python](#II)\n",
    "- [Part 3: Data Pre-processing &  Preparation](#III)\n",
    "- [Part 4: Predictive Analytics](#IV)\n",
    "- [Part 5: Optimization (Hyper Parameter Tuning)](#V)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>\n",
    "Roadmap for Building Machine Learning Models\n",
    "</summary>\n",
    "<p>\n",
    "\n",
    "\n",
    "    1. Prepare Problem  \n",
    "    a) Define The Business Objective  \n",
    "    b) Select the datasets  \n",
    "    c) Load dataset  \n",
    "    d) Load libraries  \n",
    "\n",
    "\n",
    "**Data Pre-processing**  \n",
    "This is the first step in building a machine learning model. Data pre-processing refers to the transformation of data\n",
    "before feeding it into the model. It deals with the techniques that are used to convert unusable raw data into clean \n",
    "reliable data.  \n",
    "  \n",
    "Since data collection is often not performed in a controlled manner, raw data often contains outliers \n",
    "(for example, age = 120), nonsensical data combinations (for example, model: bicycle, type: 4-wheeler), missing values, \n",
    "scale problems, and so on. Because of this, raw data cannot be fed into a machine learning model because it might \n",
    "compromise the quality of the results. As such, this is the most important step in the process of data science.  \n",
    "  \n",
    "\n",
    "    2. Summarize Data  \n",
    "    a) Descriptive statistics  \n",
    "    b) Data visualizations  \n",
    "\n",
    "    3. Prepare Data  \n",
    "    a) Data Cleaning  \n",
    "    b) Feature Selection  \n",
    "    c) Data Transformation  \n",
    "\n",
    "**Model Learning**  \n",
    "After pre-processing the data and splitting it into train/test sets (more on this later), we move on to modeling. Models \n",
    "are nothing but sets of well-defined methods called algorithms that use pre-processed data to learn patterns, which can \n",
    "later be used to make predictions. There are different types of learning algorithms, including supervised, semi-supervised, \n",
    "unsupervised, and reinforcement learning. These will be discussed later.\n",
    "  \n",
    "    4. Modeling Strategy  \n",
    "    a) Select Suitable Algorithms  \n",
    "    b) Select Training/Testing Approaches  \n",
    "    c) Train   \n",
    "  \n",
    "  \n",
    "**Model Evaluation**  \n",
    "In this stage, the models are evaluated with the help of specific performance metrics. With these metrics, we can go on to \n",
    "tune the hyperparameters of a model in order to improve it. This process is called hyperparameter optimization. We will \n",
    "repeat this step until we are satisfied with the performance.  \n",
    "  \n",
    "    4. Evaluate Algorithms  \n",
    "    a) Split-out validation dataset  \n",
    "    b) Test options and evaluation metric  \n",
    "    c) Spot Check Algorithms  \n",
    "    d) Compare Algorithms  \n",
    "  \n",
    "**Prediction**  \n",
    "Once we are happy with the results from the evaluation step, we will then move on to predictions. Predictions are made \n",
    "by the trained model when it is exposed to a new dataset. In a business setting, these predictions can be shared with \n",
    "decision makers to make effective business choices.  \n",
    "  \n",
    "    5. Improve Accuracy  \n",
    "    a) Algorithm Tuning  \n",
    "    b) Ensembles  \n",
    "\n",
    "**Model Deployment**  \n",
    "The whole process of machine learning does not just stop with model building and prediction. It also involves making use \n",
    "of the model to build an application with the new data. Depending on the business requirements, the deployment may be a \n",
    "report, or it may be some repetitive data science steps that are to be executed. After deployment, a model needs proper \n",
    "management and maintenance at regular intervals to keep it up and running.  \n",
    "\n",
    "    6. Finalize Model  \n",
    "    a) Predictions on validation dataset  \n",
    "    b) Create standalone model on entire training dataset  \n",
    "    c) Save model for later use  \n",
    "\n",
    "\n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"I\"></a>\n",
    "\n",
    "# I.  Reading Data - Exploratory Data Analysis with Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Article outline\n",
    "1. Demonstration of main Pandas methods\n",
    "2. First attempt on predicting Auto Insurance Fraud\n",
    "3. Useful resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Demonstration of main Pandas methods \n",
    "\n",
    "**[Pandas](http://pandas.pydata.org)** is a Python library that provides extensive means for data analysis. Data scientists often work with data stored in table formats like `.csv`, `.tsv`, or `.xlsx`. Pandas makes it very convenient to load, process, and analyze such tabular data using SQL-like queries. In conjunction with `Matplotlib` and `Seaborn`, `Pandas` provides a wide range of opportunities for visual analysis of tabular data.\n",
    "\n",
    "The main data structures in `Pandas` are implemented with **Series** and **DataFrame** classes. The former is a one-dimensional indexed array of some fixed data type. The latter is a two-dimensional data structure - a table - where each column contains data of the same type. You can see it as a dictionary of `Series` instances. `DataFrames` are great for representing real data: rows correspond to instances (examples, observations, etc.), and columns correspond to features of these instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set()  #  Will import Seaborn functionalities\n",
    "# we don't like warnings\n",
    "# you can comment the following 2 lines if you'd like to\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We’ll demonstrate the main methods in action by analyzing a [dataset](https://bigml.com/user/francisco/gallery/dataset/5163ad540c0b5e5b22000383) on the churn rate of telecom operator clients. Let’s read the data (using `read_csv`), and take a look at the first 5 lines using the `head` method:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disply all Columns\n",
    "pd.options.display.max_columns=70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autinsurance = pd.read_csv('insurance_claimsV4.csv').drop('Unnamed: 0', axis = 1)\n",
    "autinsurance.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autinsurance.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#autinsurance = autinsurance.drop('Unnamed: 0', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autinsurance.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autinsurance['fraud_reported'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autinsurance['fraud_reported'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autinsurance.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = autinsurance.drop('fraud_reported', axis = 1) # axis = 1 (look in columns) OR axis = 0 (look in rows)\n",
    "    \n",
    "y = autinsurance.fraud_reported"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Data split & Scaling Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from sklearn.cross_validation import train_test_split\n",
    "training_features, test_features, \\\n",
    "training_target, test_target, = train_test_split(X,y, test_size = .2, random_state = 42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Establishing a Baseline\n",
    "Establishing a baseline is one of the first steps that should be done in any machine learning\n",
    "project. A baseline is a simple model we train in the data in order to determine accuracy and\n",
    "compare to the real models we're going to try. This helps us determine whether the models\n",
    "we try are actually providing any kind of improvements or not.  \n",
    "One type of model that we can use as a baselines is called a dummy model. Dummy\n",
    "models do not learn anything from the data, they just generate their decision by following a\n",
    "rule that may or may not be related to the data. For example, a dummy model for our\n",
    "problem here is one that outputs 0 or 1 at random with a 50% chance for each; this is an\n",
    "example of a dummy rule that is not related to the data. Another dummy model is one that\n",
    "always outputs the most frequent label in the training data; this dummy model is related to\n",
    "the data, but it does not learn anything from it.  \n",
    "These kinds of dummy models are provided in scikit-learn under the dummy module. All\n",
    "of them are implemented in the DummyClassifier class, which accepts a strategy\n",
    "parameter at initialization. This strategy parameter determines which rule the model is going\n",
    "to use. Here, we're going to use the most_frequent strategy, which always returns the most\n",
    "frequent label in the training data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Using a Dummy Classifier\n",
    "\n",
    "As a first classifier, you can apply the built-in [`DummyClassifier` class from `sklearn.dummy`](https://scikit-learn.org/stable/modules/generated/sklearn.dummy.DummyClassifier.html) to set a baseline for performance of our future models.  This classifier does not actually use the feature matrix `X_digits_train`; classification decisions are made using the target vector `y_digits_train` only.  There are a few strategies, but we'll start with the `'most_frequent'` strategy.  That is, the `predict` method always returns the majority class. For our binary digit classification problem, this would be `-1` (because the `1` classification is reserved for `9`s and most of the digits are not `9`s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autinsurance['fraud_reported'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "dummy_baseline = DummyClassifier(strategy=\"most_frequent\")# all 0 \n",
    "\n",
    "dummy_baseline.fit(training_features, training_target)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having applied the `fit` method to the training data, you can use the `predict` method to see how this estimator classifies the data. Unsurprisingly, it returns a vector of all `-1`s (because that is the majority class for this data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_target_pred = dummy_baseline.predict(test_features)\n",
    "print(test_target_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can find the fraction of correct classifications using the method `score` with the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = dummy_baseline.score(test_features, test_target)\n",
    "print('The fraction of correct classifications is: {:5.3f}'.format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `dummy.score` is equivalent to explicitly comparing the entries of `y_digits_pred` to `y_digits_test`, counting the number of correct classifications, and dividing by the number of classifications in total. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For classification problems, a *confusion matrix* is a more detailed description of the accuracy of a classifier. It contains entries for the actual values as rows and predicted values as columns. This means we have:\n",
    "\n",
    "| $~$ | **predicted  (-1)** | **predicted (+1)** |\n",
    "| ---- | ----------- | ---------- |\n",
    "| **actual (-1)** |  true negative | false positive |\n",
    "| **actual (+1)** |  false negative | true positive |\n",
    "\n",
    "\n",
    "The preceding definition generalizes to the multi-class classification problems as well.\n",
    "In *Scikit-Learn*, the `confusion_matrix` function takes as arguments the actual labels followed by the predicted labels (labelled in ascending order according to the class labels). From the [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html):\n",
    "\n",
    "> `sklearn.metrics.confusion_matrix(y_true, y_pred, labels=None, sample_weight=None)`\n",
    ">\n",
    "> Compute confusion matrix to evaluate the accuracy of a classification\n",
    ">\n",
    "> By definition a confusion matrix $C$ is such that $C_{i,j}$ is equal to the number of observations known to be in group $i$ but predicted to be in group $j$.\n",
    ">\n",
    "> Thus in binary classification, the count of true negatives is $C_{0,0}$, false negatives is $C_{1,0}$, true positives is $C_{1,1}$, and false positives is $C_{0,1}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the long way of computing the accuracy score\n",
    "from sklearn.metrics import  confusion_matrix\n",
    "dummy_baselineCM = confusion_matrix(test_target,test_target_pred)\n",
    "dummy_baselineCM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import Perceptron\n",
    "\n",
    "# classifier = Perceptron() \n",
    "# classifier.fit(training_features, training_target)\n",
    "\n",
    "# accuracy = classifier.score(test_features, test_target) \n",
    "# print(\"Prediction Accuracy:{:.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Building Model (Decision Tree)\n",
    "\n",
    "\n",
    "The decision tree classes have an optional hyperparameter `criterion` that has one of two values, **`gini`** and **`entropy`**. These refer to the quantitative measure that is used to compare putative splittings of the data.\n",
    "\n",
    "<a href=\"https://en.wikipedia.org/wiki/Entropy_(information_theory)\">**Entropy**</a>: *Information entropy* is the average rate at which information is produced by a stochastic source of data.\n",
    "\n",
    "The measure of information entropy associated with each possible data value is the negative logarithm of the probability mass function for the value:\n",
    "\n",
    "$$S = - \\sum_{i = 1}  p_i \\log{ p_i} $$\n",
    "\n",
    "-----\n",
    "\n",
    "[**Gini Impurity**](https://en.wikipedia.org/wiki/Decision_tree_learning#Gini_impurity): Used by the CART (classification and regression tree) algorithm for classification trees, *Gini impurity* is a measure of how often a randomly chosen element from the set would be incorrectly labeled if it were randomly labelled according to the distribution of labels in the subset. The Gini impurity can be computed by summing the probability ${\\displaystyle p_{i}}$ of an item with label ${\\displaystyle i}$ being chosen multiplied by the probability $\\displaystyle \\sum _{k\\neq i}p_{k}=1-p_{i}$  of a mistake in categorizing that item. It reaches its minimum (zero) when all cases in the node fall into a single target category.\n",
    "\n",
    "To compute Gini impurity for a set of items with $\\displaystyle J$, classes, suppose $\\displaystyle i\\in \\{1,2,...,J\\}$ and let $\\displaystyle p_{i} $ be the fraction of items labeled with class $\\displaystyle i$ in the set.\n",
    "\n",
    "$${\\displaystyle \\operatorname {I} _{G}(p)=\\sum _{i=1}^{J}p_{i}\\sum _{k\\neq i}p_{k}=\\sum _{i=1}^{J}p_{i}(1-p_{i})=\\sum _{i=1}^{J}(p_{i}-{p_{i}}^{2})=\\sum _{i=1}^{J}p_{i}-\\sum _{i=1}^{J}{p_{i}}^{2}=1-\\sum _{i=1}^{J}{p_{i}}^{2}}$$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  2.1 First Method (using function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.tree import DecisionTreeClassifier as Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train(features, target):\n",
    "#     model = Model()\n",
    "#     model.fit(features, target)\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def predict(model, new_features):\n",
    "#     preds = model.predict(test_features)\n",
    "#     return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Assume Titanic data is loaded into titanic_feats,\n",
    "# # titanic_target and titanic_test\n",
    "# model = train(training_features, training_target)\n",
    "# predictions = predict(model, test_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  2.2 Second Method "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DecisionTreeModel = DecisionTreeClassifier(criterion='entropy', random_state=42 , max_depth=4)#  \n",
    "\n",
    "DecisionTreeModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "DecisionTreeModel.fit(training_features, training_target)  # Training input and its Target variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DT_Pred = DecisionTreeModel.predict(test_features) # I already Know y_test  # 200 variables "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2  Making the Confusion Matrix\n",
    "**Accuracy** is perhaps the most intuitive performance measure. It is simply the ratio of correctly predicted observations.  \n",
    "**Precision**: Precision looks at the ratio of correct positive observations   \n",
    "**Recall** : Recall is also known as sensitivity or true positive rate. It is the ratio of correctly predicted positive events   \n",
    "**F1 Score** : The F1 Score is the weighted average of Precision and recall. Therefore, this score takes both false postives and false negatives into account   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "#from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import machine learning modules\n",
    "# from sklearn.ensemble import GradientBoostingClassifier, partial_dependence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "CMTD = confusion_matrix(test_target,DT_Pred) # Compare the predicted target varaible to the orginal target variable\n",
    "CMTD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#target = 'fraud_reported'\n",
    "CMTD = pd.crosstab(test_target,DT_Pred, rownames=['Actual'], colnames=['Predicted'])\n",
    "fig, (ax1) = plt.subplots(ncols=1, figsize=(5,5))\n",
    "sns.heatmap(CMTD, \n",
    "            xticklabels=['Fraudulant', 'Legit'],\n",
    "            yticklabels=['Fraudulant', 'Legit'],\n",
    "            annot=True,ax=ax1,\n",
    "            linewidths=.2,linecolor=\"Darkblue\", cmap=\"Blues\")\n",
    "plt.title('Confusion Matrix', fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Accuracy Score\n",
    "ADT= accuracy_score(test_target, DT_Pred)\n",
    "\n",
    "print(\" Decision Tree Prediction Accuracy : {:.2f}%\".format(ADT * 100))\n",
    "# print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4  Computing the Accuracy of a Binary Classifier\n",
    "\n",
    "The most basic way to assess performance is to compare the total number of correct predictions and the total number of observations.  This is the **accuracy**. Using the diagram of our confusion matrix above, the accuracy can be written as\n",
    "\n",
    "$$\\text{accuracy} = \\frac{\\mathtt{tp} + \\mathtt{tn}}{\\mathtt{tn} + \\mathtt{tp} + \\mathtt{fn} + \\mathtt{fp}}$$\n",
    "\n",
    "where $\\mathtt{tn}$, $\\mathtt{tp}$, $\\mathtt{fn}$, and $\\mathtt{fp}$ are the number of true negatives, true positives, false negatives, and false positives respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import classification_report\n",
    "# #d = DecisionTreeModel.fit(X_train.values, y_train.values.copy(), 50)\n",
    "# #\n",
    "# #preds = predict(X_test, d)\n",
    "# print(classification_report(test_target,DT_Pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"feature-importance\"></a>\n",
    "\n",
    "### 2.3  Plot feature importances\n",
    "\n",
    "A fantastic characteristic of many ensemble models is that you have the ability to interpret the feature importance. As you learned with Decision Trees, the most important features are selected first during the construction of a tree. Using the gini or information gain generated from using a feature to make a split, a feature importance score can be calculated.\n",
    "\n",
    "In the case of ensembles, these feature importance scores are aggregated over all of the trees within the ensemble. `scikit-learn` conveniently calculates a `.feature_importance_` score for many of their ensemble implementations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DecisionTreeModel.fit(training_features, training_target)\n",
    "### Verification:\n",
    "results = pd.DataFrame(index= training_features.columns, data={'importance':DecisionTreeModel.feature_importances_})\n",
    "print('Feature importances:\\n{}'.format(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot feature importances\n",
    "plt.rcParams['figure.figsize'] = 20,30\n",
    "plt.title('Normalized Feature Importances')\n",
    "sns.barplot(x = DecisionTreeModel.feature_importances_, y =training_features.columns, orient = 'h')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = pd.DataFrame({'Importance Coef' :DecisionTreeModel.feature_importances_ , 'Features' : training_features.columns})\n",
    "feature_importances.nlargest(10, 'Importance Coef')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = feature_importances.nlargest(135, 'Importance Coef')\n",
    "\n",
    "features =[x for x in features['Features'] if x!=0]\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autinsurance = autinsurance[['insured_hobbies_chess',\n",
    " 'vehicle_claim',\n",
    " 'incident_severity_Total Loss',\n",
    " 'insured_hobbies_cross-fit',\n",
    " 'incident_severity_Minor Damage',\n",
    " 'insured_hobbies_camping',\n",
    " 'auto_model_Civic',\n",
    " 'incident_state_WV',\n",
    " 'insured_occupation_handlers-cleaners','fraud_reported']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4  Plot Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['PATH'] = os.environ['PATH']+';'+os.environ['CONDA_PREFIX']+r\"\\Library\\bin\\graphviz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from six import StringIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import six\n",
    "import sys\n",
    "sys.modules['sklearn.externals.six'] = six"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install pydotplus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.externals.six import StringIO  \n",
    "from IPython.display import Image  \n",
    "import pydotplus\n",
    "\n",
    "dot_data = StringIO()\n",
    "export_graphviz(DecisionTreeModel, out_file=dot_data,  \n",
    "                filled=True, rounded=True,\n",
    "                special_characters=True,feature_names = X.columns,class_names=['0','1'])\n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
    "graph.write_png('Auto-Inssurance.png')\n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
